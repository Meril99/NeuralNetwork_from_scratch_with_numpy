{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fb275c-be24-44e6-a767-f14fa00c444a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1000,1) (128,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_64463/3536824042.py\u001b[0m in \u001b[0;36m<cell line: 235>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m \u001b[0mneural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_64463/3536824042.py\u001b[0m in \u001b[0;36mneural_network\u001b[0;34m(test_data_x, test_data_y, train_data_x, train_label_array, n1, n2, learning_rate, n_iter, batch)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0ma1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;31m# A2 = activations['A2']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_64463/3536824042.py\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(X, W1, W2, W3, b1, b2, b3)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1000,1) (128,1) "
     ]
    }
   ],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "import math\n",
    "from sklearn.datasets import make_blobs\n",
    "from tqdm import tqdm #barre de progression taquadoum\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#sav files\n",
    "file1='t10k-images.idx3-ubyte'\n",
    "file2='t10k-labels.idx1-ubyte'\n",
    "file3='train-images.idx3-ubyte'\n",
    "file4='train-labels.idx1-ubyte'\n",
    "\n",
    "def read_idx(filename):\n",
    "    '''Reads an idx file and returns an ndarray'''\n",
    "    with open(filename, 'rb') as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "# def preprocessing(arr3d_array):\n",
    "#     arr2d_array=arr3d_array.reshape(arr3d_array.shape[0],arr3d_array.shape[1]*arr3d_array.shape[2])\n",
    "#     arr2d_array = normalize(arr2d_array)\n",
    "#     return arr2d_array\n",
    "  \n",
    "def preprocessing(arr3d_array):\n",
    "    arr2d_array=arr3d_array.reshape(arr3d_array.shape[0],arr3d_array.shape[1]*arr3d_array.shape[2])\n",
    "    arr2d_array = (arr2d_array - arr2d_array.min())/ (arr2d_array.max() - arr2d_array.min())\n",
    "    return arr2d_array\n",
    "    \n",
    "\n",
    "def preprocessing_label(vector):\n",
    "    matrice = np.zeros((vector.size, 10))\n",
    "    matrice[np.arange(vector.size), vector] = 1\n",
    "    return matrice\n",
    "    \n",
    "    \n",
    "\n",
    "def graphic_view():\n",
    "    X, y = make_blobs(n_samples=60000, n_features=28*28, centers=10, random_state=0)\n",
    "    y = y.reshape((y.shape[0], 1))\n",
    "\n",
    "    print(X.shape,y.shape)\n",
    "    print('dimensions de X:', X.shape)\n",
    "    print('dimensions de y:', y.shape)\n",
    "\n",
    "    plt.scatter(X[:,0], X[:, 1], c=y, cmap='summer')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def initialisation(n0, n1, n2,n3):\n",
    "    W1 = np.random.randn(n0, 1)\n",
    "    b1 = np.zeros((n1, 1))\n",
    "    W2 = np.random.randn(n1, 1)\n",
    "    b2 = np.zeros((n2, 1))\n",
    "    W3 = np.random.randn(n2, 1)\n",
    "    b3 = np.zeros((n3, 1))\n",
    "    return W1,W2,W3,b1,b2,b3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sigmoide(z_i):\n",
    "    return 1/(1+np.exp(-z_i))\n",
    "\n",
    "# normaliser poids\n",
    "def softmax(array):\n",
    "    return (np.exp(array - array.max()))/np.sum(np.exp(array - array.max()))\n",
    "\n",
    "\n",
    "def dsigmoid(x):\n",
    "    return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def forward_propagation(X,W1,W2,W3,b1,b2,b3):\n",
    "\n",
    "    \n",
    "\n",
    "    Z1 = X.dot(W1) + b1\n",
    "    A1 = sigmoide(Z1)\n",
    "\n",
    "    Z2 = A1.dot(W2) + b2\n",
    "    A2 = sigmoide(Z2)\n",
    "    \n",
    "    Z3 = A2.dot(W3) + b3\n",
    "    A3 = sigmoide(Z3)\n",
    "\n",
    "    \n",
    "    return A1,A2,A3\n",
    "\n",
    "    \n",
    "# un batch  après l'autre\n",
    "#On prend la transposée de X et de y\n",
    "def back_propagation(X, y, w1,w2,w3,b1,b2,b3, A1,A2,A3):\n",
    "    m = y.shape[1]\n",
    "    dZ3 = A3 - y\n",
    "    dW3 = 1 / m * dZ3.dot(A2.T)\n",
    "    #pour éviter que la dimension 1 disparaisse et des erreurs de broadcasting on met keepdims à true\n",
    "    db3 = 1 / m * np.sum(dZ3, axis=1, keepdims = True)\n",
    "    dZ2 = A2 - y\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2, axis=1, keepdims = True)\n",
    "    dZ1 = np.dot(W2.T, dZ2) * A1 * (1 - A1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1, axis=1, keepdims = True)\n",
    "    return dW1,dW2,dW3,db1,db2,db3\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def update(dW1,dW2,dW3,db1,db2,db3, w1,w2,w3,b1,b2,b3, learning_rate):\n",
    "    w1new = W1 - learning_rate * dW1\n",
    "    b1new = b1 - learning_rate * db1\n",
    "    w2new = W2 - learning_rate * dW2\n",
    "    b2new = b2 - learning_rate * db2\n",
    "    w3new = W3 - learning_rate * dW3\n",
    "    b3new = b3 - learning_rate * db3\n",
    "    return w1new,w2new,w3new,b1new,b2new,b3new\n",
    "\n",
    "\n",
    "def compute_error(A,y):\n",
    "    epsilon = 1e-15\n",
    "    return 1 / len(y) * np.sum(-y * np.log(A + epsilon) - (1 - y) * np.log(1 - A + epsilon))\n",
    "\n",
    "def compute_batch_error(test_data_x_test,test_data_label_test,updated_w1,updated_w2,updated_w3,neb1,newb2,newb3):\n",
    "    error_total=np.empty([0,test_data_x_test.shape[0]],dtype=float)\n",
    "    for j in range(0,test_data_x_test.shape[0]):\n",
    "        new_test_data,new_z1__,new_z2__,new_z3__,new_a1__,new_a2__,new_a3__=forward_propagation(test_data_x_test[j],w1,w2,w3,b1,b2,b3)\n",
    "\n",
    "        indice_max_y=np.argmax(test_data_label_test[j],axis=1)\n",
    "       \n",
    "        indice_max_a=np.argmax(new_a3__,axis=1)\n",
    "       \n",
    "        error_per_batch=1-np.mean(indice_max_a==indice_max_y)\n",
    "        error_total=np.append(error_total,error_per_batch)\n",
    "        \n",
    "    return np.mean(error_total)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def neural_network(test_data_x,test_data_y,train_data_x, train_label_array, n1=128,n2=64, learning_rate = 0.1, n_iter = 1000, batch=60):\n",
    "    train_data_x=preprocessing(train_data_x)\n",
    "    train_label_array=preprocessing_label(train_label_array)\n",
    "    test_data_x=preprocessing(test_data_x)\n",
    "    test_data_y=preprocessing_label(test_data_y)\n",
    "    \n",
    "    sets_list=np.array_split(train_data_x, batch)\n",
    "    sets_array=np.array(sets_list)\n",
    "    y_sets=np.array_split(train_label_array, batch)\n",
    "    y_sets_array=np.array(y_sets)\n",
    "    batch_array=sets_array\n",
    "    \n",
    "    x_tests=np.array_split(test_data_x, batch/6)\n",
    "    x_tests=np.array(x_tests)\n",
    "    \n",
    "    y_tests=np.array_split(test_data_y, batch/6)\n",
    "    y_tests=np.array(y_tests)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # initialisation parametres\n",
    "    n0 = train_data_x.shape[1]\n",
    "    n3 = train_label_array.shape[1]\n",
    "    np.random.seed(0)\n",
    "    w1,w2,w3,b1,b2,b3 = initialisation(n0, n1, n2, n3)\n",
    "\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    history = []\n",
    "\n",
    "    # gradient descent\n",
    "    for i in tqdm(range(n_iter)):\n",
    "        for j in (range(batch)):\n",
    "            a1,a2,a3 = forward_propagation(batch_array[j], w1,w2,w3,b1,b2,b3)\n",
    "        # A2 = activations['A2']\n",
    "\n",
    "        # Plot courbe d'apprentissage\n",
    "#         train_loss.append(log_loss(y.flatten(), A2.flatten()))\n",
    "#         y_pred = predict(X, parametres)\n",
    "#         train_acc.append(accuracy_score(y.flatten(), y_pred.flatten()))\n",
    "        \n",
    "        # history.append([parametres.copy(), train_loss, train_acc, i])\n",
    "\n",
    "        # mise a jour\n",
    "            dW1_,dW2_,dW3_,db1_,db2_,db3_ = back_propagation(batch_array[j], y_sets_array[j], w1,w2,w3,b1,b2,b3, a1,a2,a3)\n",
    "            w1new_,w2new_,w3new_,b1new_,b2new_,b3new_ = update(dW1_,dW2_,dW3_,db1_,db2_,db3_, w1,w2,w3,b1,b2,b3, learning_rate)\n",
    "            res=compute_batch_error(test_data_x_test,test_data_label_test,w1new_,w2new_,w3new_,b1new_,b2new_,b3new)\n",
    "\n",
    "\n",
    "    # plt.figure(figsize=(12, 4))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.plot(train_loss, label='train loss')\n",
    "    # plt.legend()\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.plot(train_acc, label='train acc')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "x_train,y_train,x_test,y_test=read_idx(file3),read_idx(file4),read_idx(file1),read_idx(file2)\n",
    "\n",
    "\n",
    "\n",
    "neural_network(x_test,y_test,x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a61d5-4c99-41f1-bf9c-001ab5a66dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('y_test shape')\n",
    "print(y_tests.shape)\n",
    "print('y_tests[0:6].shape')\n",
    "print(y_tests[0:6].shape)\n",
    "print(y_tests[0:6])\n",
    "print('y_test[0] shape')\n",
    "print(y_tests[0].shape)\n",
    "print(y_tests[0])\n",
    "\n",
    "print('y_sets_array shape')\n",
    "print(y_sets_array.shape)\n",
    "print('y_sets_array[0:6].shape')\n",
    "print(y_sets_array[0:6].shape)\n",
    "print(y_sets_array[0:6])\n",
    "print('y_sets_array[0] shape')\n",
    "print(y_sets_array[0].shape)\n",
    "print(y_sets_array[0])\n",
    "\n",
    "\n",
    "print('x_test shape')\n",
    "print(x_tests.shape)\n",
    "print('x_tests[0:6].shape')\n",
    "print(x_tests[0:6].shape)\n",
    "print(x_tests[0:6])\n",
    "print('x_test[0] shape')\n",
    "print(x_tests[0].shape)\n",
    "print(x_tests[0])\n",
    "\n",
    "\n",
    "print('batch_array shape')\n",
    "print(batch_array.shape)\n",
    "print('batch_array[0:6].shape')\n",
    "print(batch_array[0:6].shape)\n",
    "print(batch_array[0:6])\n",
    "print('batch_array[0] shape')\n",
    "print(batch_array[0].shape)\n",
    "print(batch_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d04007a-bc5d-4a7b-8af2-caf6ceb9ae89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018c9e7-dae9-4e9c-86c0-750670625969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2e18c-90b3-408e-9016-fb157849da6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3063f-b54f-4766-af07-53ffb1366382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918e810-ee73-476a-9c6b-d7c43a5ed349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f3b111-9170-4f0d-a44b-5ac0e7bdf0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65faa3c-d545-4008-abc7-536d4b46c128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455881e5-48c7-4dcc-b712-8ba980e5a722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
